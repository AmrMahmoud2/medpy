<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8">
    
    <title>medpy.metric.image &mdash; MedPy 0.4.0 documentation</title>
    
    <link rel="stylesheet" type="text/css" href="../../../_static/css/spc-bootstrap.css">
    <link rel="stylesheet" type="text/css" href="../../../_static/css/spc-extend.css">
    <link rel="stylesheet" href="../../../_static/scipy.css" type="text/css" >
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" >
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../../',
        VERSION:     '0.4.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../../_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript" src="../../../_static/js/copybutton.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" >
    <link rel="search" title="Search" href="../../../search.html" >
    <link rel="top" title="MedPy 0.4.0 documentation" href="../../../index.html" >
    <link rel="up" title="Module code" href="../../index.html" > 
  </head>
  <body>

  <div class="container">
    <div class="header">
    </div>
  </div>


    <div class="container">
      <div class="main">
        
	<div class="row-fluid">
	  <div class="span12">
	    <div class="spc-navbar">
              
    <ul class="nav nav-pills pull-left">
        <li class="active"><a href="https://github.com/loli/medpy/">GitHub</a></li>
        <li class="active"><a href="https://pypi.python.org/pypi/MedPy/">PyPi</a></li>
	
        <li class="active"><a href="../../../index.html">MedPy 0.4.0 documentation</a></li>
	
          <li class="active"><a href="../../index.html" accesskey="U">Module code</a></li> 
    </ul>
              
              
    <ul class="nav nav-pills pull-right">
      <li class="active">
        <a href="../../../genindex.html" title="General Index"
           accesskey="I">index</a>
      </li>
      <li class="active">
        <a href="../../../py-modindex.html" title="Python Module Index"
           >modules</a>
      </li>
    </ul>
              
	    </div>
	  </div>
	</div>
        

	<div class="row-fluid">
      <div class="spc-rightsidebar span3">
        <div class="sphinxsidebarwrapper">
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="../../../search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
          <div class="span9">
            
        <div class="bodywrapper">
          <div class="body" id="spc-section-body">
            
  <h1>Source code for medpy.metric.image</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright (C) 2013 Oskar Maier</span>
<span class="c1"># </span>
<span class="c1"># This program is free software: you can redistribute it and/or modify</span>
<span class="c1"># it under the terms of the GNU General Public License as published by</span>
<span class="c1"># the Free Software Foundation, either version 3 of the License, or</span>
<span class="c1"># (at your option) any later version.</span>
<span class="c1"># </span>
<span class="c1"># This program is distributed in the hope that it will be useful,</span>
<span class="c1"># but WITHOUT ANY WARRANTY; without even the implied warranty of</span>
<span class="c1"># MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the</span>
<span class="c1"># GNU General Public License for more details.</span>
<span class="c1"># </span>
<span class="c1"># You should have received a copy of the GNU General Public License</span>
<span class="c1"># along with this program.  If not, see &lt;http://www.gnu.org/licenses/&gt;.</span>
<span class="c1">#</span>
<span class="c1"># author Oskar Maier</span>
<span class="c1"># version r0.1.0</span>
<span class="c1"># since 2013-07-09</span>
<span class="c1"># status Release</span>

<span class="c1"># build-in modules</span>

<span class="c1"># third-party modules</span>
<span class="kn">import</span> <span class="nn">numpy</span>

<span class="c1"># own modules</span>
<span class="kn">from</span> <span class="nn">..core</span> <span class="k">import</span> <span class="n">ArgumentError</span>

<span class="c1"># code</span>
<div class="viewcode-block" id="mutual_information"><a class="viewcode-back" href="../../../generated/medpy.metric.image.mutual_information.html#medpy.metric.image.mutual_information">[docs]</a><span class="k">def</span> <span class="nf">mutual_information</span><span class="p">(</span><span class="n">i1</span><span class="p">,</span> <span class="n">i2</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">256</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the mutual information (MI) (a measure of entropy) between two images.</span>

<span class="sd">    MI is not real metric, but a symmetric and nonnegative similarity measures that</span>
<span class="sd">    takes high values for similar images. Negative values are also possible.</span>
<span class="sd">    </span>
<span class="sd">    Intuitively, mutual information measures the information that ``i1`` and ``i2`` share: it</span>
<span class="sd">    measures how much knowing one of these variables reduces uncertainty about the other.</span>
<span class="sd">    </span>
<span class="sd">    The Entropy is defined as:</span>
<span class="sd">    </span>
<span class="sd">    .. math::</span>
<span class="sd">    </span>
<span class="sd">        H(X) = - \sum_i p(g_i) * ln(p(g_i)</span>

<span class="sd">    with :math:`p(g_i)` being the intensity probability of the images grey value :math:`g_i`.</span>
<span class="sd">    </span>
<span class="sd">    Assuming two images :math:`R` and :math:`T`, the mutual information is then computed by comparing the</span>
<span class="sd">    images entropy values (i.e. a measure how well-structured the common histogram is).</span>
<span class="sd">    The distance metric is then calculated as follows:</span>
<span class="sd">    </span>
<span class="sd">    .. math::</span>
<span class="sd">    </span>
<span class="sd">        MI(R,T) = H(R) + H(T) - H(R,T) = H(R) - H(R|T) = H(T) - H(T|R)</span>
<span class="sd">    </span>
<span class="sd">    A maximization of the mutual information is equal to a minimization of the joint</span>
<span class="sd">    entropy.</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    i1 : array_like</span>
<span class="sd">        The first image.</span>
<span class="sd">    i2 : array_like</span>
<span class="sd">        The second image.</span>
<span class="sd">    bins : integer</span>
<span class="sd">        The number of histogram bins (squared for the joined histogram).</span>
<span class="sd">    </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    mutual_information : float</span>
<span class="sd">        The mutual information distance value between the supplied images.</span>
<span class="sd">    </span>
<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ArgumentError</span>
<span class="sd">        If the supplied arrays are of different shape.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># pre-process function arguments</span>
    <span class="n">i1</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">i1</span><span class="p">)</span>
    <span class="n">i2</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">i2</span><span class="p">)</span>
    
    <span class="c1"># validate function arguments</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">i1</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">i2</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">ArgumentError</span><span class="p">(</span><span class="s1">&#39;the two supplied array-like sequences i1 and i2 must be of the same shape&#39;</span><span class="p">)</span>
    
    <span class="c1"># compute i1 and i2 histogram range</span>
    <span class="n">i1_range</span> <span class="o">=</span> <span class="n">__range</span><span class="p">(</span><span class="n">i1</span><span class="p">,</span> <span class="n">bins</span><span class="p">)</span>
    <span class="n">i2_range</span> <span class="o">=</span> <span class="n">__range</span><span class="p">(</span><span class="n">i2</span><span class="p">,</span> <span class="n">bins</span><span class="p">)</span>
    
    <span class="c1"># compute joined and separated normed histograms</span>
    <span class="n">i1i2_hist</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">histogram2d</span><span class="p">(</span><span class="n">i1</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">i2</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">bins</span><span class="o">=</span><span class="n">bins</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="p">[</span><span class="n">i1_range</span><span class="p">,</span> <span class="n">i2_range</span><span class="p">])</span> <span class="c1"># Note: histogram2d does not flatten array on its own</span>
    <span class="n">i1_hist</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">i1</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="n">bins</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="n">i1_range</span><span class="p">)</span>
    <span class="n">i2_hist</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">i2</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="n">bins</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="n">i2_range</span><span class="p">)</span>
    
    <span class="c1"># compute joined and separated entropy</span>
    <span class="n">i1i2_entropy</span> <span class="o">=</span> <span class="n">__entropy</span><span class="p">(</span><span class="n">i1i2_hist</span><span class="p">)</span>
    <span class="n">i1_entropy</span> <span class="o">=</span> <span class="n">__entropy</span><span class="p">(</span><span class="n">i1_hist</span><span class="p">)</span>
    <span class="n">i2_entropy</span> <span class="o">=</span> <span class="n">__entropy</span><span class="p">(</span><span class="n">i2_hist</span><span class="p">)</span>
    
    <span class="c1"># compute and return the mutual information distance</span>
    <span class="k">return</span> <span class="n">i1_entropy</span> <span class="o">+</span> <span class="n">i2_entropy</span> <span class="o">-</span> <span class="n">i1i2_entropy</span></div>

<span class="k">def</span> <span class="nf">__range</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">bins</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;Compute the histogram range of the values in the array a according to</span>
<span class="sd">    scipy.stats.histogram.&#39;&#39;&#39;</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="n">a_max</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
    <span class="n">a_min</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">min</span><span class="p">()</span>
    <span class="n">s</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">a_max</span> <span class="o">-</span> <span class="n">a_min</span><span class="p">)</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">bins</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">a_min</span> <span class="o">-</span> <span class="n">s</span><span class="p">,</span> <span class="n">a_max</span> <span class="o">+</span> <span class="n">s</span><span class="p">)</span>
 
<span class="k">def</span> <span class="nf">__entropy</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;Compute entropy of the flattened data set (e.g. a density distribution).&#39;&#39;&#39;</span>
    <span class="c1"># normalize and convert to float</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>
    <span class="c1"># for each grey-value g with a probability p(g) = 0, the entropy is defined as 0, therefore we remove these values and also flatten the histogram</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">data</span><span class="p">)]</span>
    <span class="c1"># compute entropy</span>
    <span class="k">return</span> <span class="o">-</span><span class="mf">1.</span> <span class="o">*</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">data</span> <span class="o">*</span> <span class="n">numpy</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>
    
</pre></div>

          </div>
        </div>
          </div>
        </div>
      </div>
    </div>

    <div class="container container-navbar-bottom">
      <div class="spc-navbar">
        
      </div>
    </div>
    <div class="container">
    <div class="footer">
    <div class="row-fluid">
    <ul class="inline pull-left">
      <li>
        &copy; Copyright 2013-2019, Oskar Maier.
      </li>
      <li>
      Last updated on Feb 14, 2019.
      </li>
      <li>
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.6.7.
      </li>
    </ul>
    </div>
    </div>
    </div>
  </body>
</html>
